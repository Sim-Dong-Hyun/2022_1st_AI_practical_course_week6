{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import glob\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
        "\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For static images:\n",
        "IMAGE_FILES = glob.glob(\"./selfie_pic/*\")\n",
        "BG_COLOR = (192, 192, 192) # gray\n",
        "MASK_COLOR = (255, 255, 255) # white\n",
        "with mp_selfie_segmentation.SelfieSegmentation(model_selection=0) as selfie_segmentation:\n",
        "    for idx, file in enumerate(IMAGE_FILES):\n",
        "        image = cv2.imread(file)\n",
        "\n",
        "        image_height, image_width, _ = image.shape\n",
        "        # Convert the BGR image to RGB before processing.\n",
        "        results = selfie_segmentation.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # Draw selfie segmentation on the background image.\n",
        "        # To improve segmentation around boundaries, consider applying a joint\n",
        "        # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
        "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
        "        # Generate solid color images for showing the output selfie segmentation mask.\n",
        "        fg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "        fg_image[:] = MASK_COLOR\n",
        "        bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "        bg_image[:] = BG_COLOR\n",
        "        output_image = np.where(condition, fg_image, bg_image)\n",
        "\n",
        "        plt.imshow(output_image)\n",
        "\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_selfie_segmentation.SelfieSegmentation() as selfie_segmentation:\n",
        "  for idx, file in enumerate(IMAGE_FILES):\n",
        "    image = cv2.imread(file)\n",
        "    results = selfie_segmentation.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)) #opencv는 BGR을 사용하지만 mediapipe는 RGB이기 때문에 변경\n",
        "\n",
        "    # bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "    # bg_image[:] = BG_COLOR\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(image, (55,55),0)\n",
        "    condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
        "    output_image = np.where(condition, image, blurred_image)\n",
        "\n",
        "    output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(output_image)\n",
        "\n",
        "\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "width = int(cap.get(3)) ; height = int(cap.get(4))\n",
        "fps = 30.0\n",
        "now = datetime.datetime.now()\n",
        "vid_file_name = \"./selfie_vid/{}_out.mp4\".format(now.strftime(\"%m%d_%H%M%S\"))\n",
        "vid_file = cv2.VideoWriter(vid_file_name, fourcc, fps, (width, height))\n",
        "\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "# for colab or recorded vid\n",
        "# selfie_orgin = \"./selfie_vid/0227_195717.mp4\"\n",
        "# cap = cv2.VideoCapture(selfie_orgin)\n",
        "\n",
        "with mp_selfie_segmentation.SelfieSegmentation(model_selection=1) as selfie_segmentation:\n",
        "    bg_image = cv2.imread('./selfie_bg/milky_way.png')\n",
        "    bg_image = cv2.resize(bg_image, dsize = (640, 480))\n",
        "    bg_image = cv2.GaussianBlur(bg_image, (15, 15), 0)\n",
        "\n",
        "    # bg_image = np.zeros(image.shape, dtype=np.uint8)\n",
        "    # bg_image[:] = (192, 192, 192)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            print(\"Ignoring empty frame\")\n",
        "            break\n",
        "\n",
        "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
        "        # To improve performance, optionally mark the image as not writeable to\n",
        "        # pass by reference.\n",
        "        image.flags.writeable = False\n",
        "        results = selfie_segmentation.process(image)\n",
        "\n",
        "        image.flags.writeable = True\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Draw selfie segmentation on the background image.\n",
        "        # To improve segmentation around boundaries, consider applying a joint\n",
        "        # bilateral filter to \"results.segmentation_mask\" with \"image\".\n",
        "        condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
        "\n",
        "        output_image = np.where(condition, image, bg_image)\n",
        "\n",
        "        cv2.imshow('MediaPipe Selfie Segmentation', output_image)\n",
        "\n",
        "        # vid_file.write(output_image)\n",
        "\n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n",
        "vid_file.release()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}